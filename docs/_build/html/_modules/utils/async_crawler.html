<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>utils.async_crawler &mdash; CodeHub 1.0 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            CodeHub
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">CodeHub</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">CodeHub</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">utils.async_crawler</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for utils.async_crawler</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">httpx</span>
<span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">import</span> <span class="nn">html.parser</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">TypeAlias</span>
<span class="kn">import</span> <span class="nn">urllib.parse</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="n">FilterFunc</span><span class="p">:</span> <span class="n">TypeAlias</span> <span class="o">=</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span>

<div class="viewcode-block" id="UrlFilter"><a class="viewcode-back" href="../../utils.html#utils.async_crawler.UrlFilter">[docs]</a><span class="k">class</span> <span class="nc">UrlFilter</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class used to filter URLs based on given parameters.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    allowed_domains : set[str] | None</span>
<span class="sd">        A set of domains that are allowed.</span>
<span class="sd">    allowed_schemes : set[str] | None</span>
<span class="sd">        A set of URL schemes that are allowed.</span>
<span class="sd">    allowed_filetypes : set[str] | None</span>
<span class="sd">        A set of file extensions that are allowed.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    url_filter(base: str, url: str) -&gt; str | None:</span>
<span class="sd">        Applies the defined filters to a given URL and returns the URL if it passes all the filters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">allowed_domains</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">allowed_schemes</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">allowed_filetypes</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allowed_domains</span> <span class="o">=</span> <span class="n">allowed_domains</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allowed_schemes</span> <span class="o">=</span> <span class="n">allowed_schemes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allowed_filetypes</span> <span class="o">=</span> <span class="n">allowed_filetypes</span>

<div class="viewcode-block" id="UrlFilter.url_filter"><a class="viewcode-back" href="../../utils.html#utils.async_crawler.UrlFilter.url_filter">[docs]</a>    <span class="k">def</span> <span class="nf">url_filter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Applies the defined filters to a given URL.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            base (str): The base URL to resolve against if the given URL is relative.</span>
<span class="sd">            url (str): The URL to filter.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str | None: The URL if it passes all the filters; otherwise None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">url</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">parse</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">url</span><span class="p">)</span>
        <span class="n">url</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">parse</span><span class="o">.</span><span class="n">urldefrag</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
        <span class="n">parsed</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">parse</span><span class="o">.</span><span class="n">urlparse</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">allowed_schemes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">parsed</span><span class="o">.</span><span class="n">scheme</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">allowed_schemes</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">allowed_domains</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">parsed</span><span class="o">.</span><span class="n">netloc</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">allowed_domains</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="n">ext</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">parsed</span><span class="o">.</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="n">suffix</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">allowed_filetypes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ext</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">allowed_filetypes</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">url</span></div></div>

<div class="viewcode-block" id="UrlParser"><a class="viewcode-back" href="../../utils.html#utils.async_crawler.UrlParser">[docs]</a><span class="k">class</span> <span class="nc">UrlParser</span><span class="p">(</span><span class="n">html</span><span class="o">.</span><span class="n">parser</span><span class="o">.</span><span class="n">HTMLParser</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class used to parse HTML and extract URLs.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    base : str</span>
<span class="sd">        The base URL to resolve against if the extracted URLs are relative.</span>
<span class="sd">    found_links : set</span>
<span class="sd">        A set to store the extracted URLs.</span>
<span class="sd">    filter_func : FilterFunc</span>
<span class="sd">        A filter function to apply to the extracted URLs.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    handle_starttag(tag: str, attrs: list[tuple[str, str]]) -&gt; None:</span>
<span class="sd">        Extracts and filters URLs from the &quot;href&quot; attribute of &quot;a&quot; elements.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">url_filter</span><span class="p">:</span> <span class="n">FilterFunc</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base</span> <span class="o">=</span> <span class="n">base</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">found_links</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filter_func</span> <span class="o">=</span> <span class="n">url_filter</span>

<div class="viewcode-block" id="UrlParser.handle_starttag"><a class="viewcode-back" href="../../utils.html#utils.async_crawler.UrlParser.handle_starttag">[docs]</a>    <span class="k">def</span> <span class="nf">handle_starttag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">attrs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># find all links</span>
        <span class="k">if</span> <span class="n">tag</span> <span class="o">!=</span> <span class="s2">&quot;a&quot;</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">for</span> <span class="n">attr</span><span class="p">,</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">attrs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">attr</span> <span class="o">!=</span> <span class="s2">&quot;href&quot;</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filter_func</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base</span><span class="p">,</span> <span class="n">url</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">url</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">found_links</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">url</span><span class="p">)</span></div></div>

<div class="viewcode-block" id="PasteParser"><a class="viewcode-back" href="../../utils.html#utils.async_crawler.PasteParser">[docs]</a><span class="k">class</span> <span class="nc">PasteParser</span><span class="p">(</span><span class="n">html</span><span class="o">.</span><span class="n">parser</span><span class="o">.</span><span class="n">HTMLParser</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class used to parse HTML and extract code snippet sources.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    source_name : str | None</span>
<span class="sd">        The name of the code snippet source.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    handle_starttag(tag: str, attrs: list[tuple[str, str | None]]) -&gt; None:</span>
<span class="sd">        Extracts the name of the code snippet source from the &quot;class&quot; attribute of &quot;div&quot; elements.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">source_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="PasteParser.handle_starttag"><a class="viewcode-back" href="../../utils.html#utils.async_crawler.PasteParser.handle_starttag">[docs]</a>    <span class="k">def</span> <span class="nf">handle_starttag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">attrs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">tag</span> <span class="o">!=</span> <span class="s2">&quot;div&quot;</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">for</span> <span class="n">attr</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">attrs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">attr</span> <span class="o">!=</span> <span class="s2">&quot;class&quot;</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="s1">&#39;source&#39;</span> <span class="ow">in</span> <span class="n">value</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">source_name</span> <span class="o">=</span> <span class="n">value</span></div></div>

<div class="viewcode-block" id="Crawler"><a class="viewcode-back" href="../../utils.html#utils.async_crawler.Crawler">[docs]</a><span class="k">class</span> <span class="nc">Crawler</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">client</span><span class="p">:</span> <span class="n">httpx</span><span class="o">.</span><span class="n">AsyncClient</span><span class="p">,</span> <span class="n">starting_url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">filter_func</span><span class="p">:</span><span class="n">FilterFunc</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">rate_limiter</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a Crawler with the given client, starting URL, filter function, number of workers, limit, and rate limiter.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            client (httpx.AsyncClient): The HTTP client to use for making requests.</span>
<span class="sd">            starting_url (str): The URL to start crawling from.</span>
<span class="sd">            filter_func (FilterFunc): A filter function to apply to the extracted URLs.</span>
<span class="sd">            workers (int, optional): The number of workers to use for crawling. Defaults to 10.</span>
<span class="sd">            limit (int, optional): The maximum number of URLs to crawl. Defaults to 100.</span>
<span class="sd">            rate_limiter (bool, optional): Whether to limit the rate of requests. If true, sets the number of workers to 1 and the delay between requests to 1.5 seconds. Defaults to False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__client</span> <span class="o">=</span> <span class="n">client</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">starting_url</span> <span class="o">=</span> <span class="n">starting_url</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">todo</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">=</span> <span class="n">workers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limit</span> <span class="o">=</span> <span class="n">limit</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filter_func</span> <span class="o">=</span> <span class="n">filter_func</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">delay</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">rate_limiter</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">delay</span> <span class="o">=</span> <span class="mf">1.5</span>

<div class="viewcode-block" id="Crawler.run"><a class="viewcode-back" href="../../utils.html#utils.async_crawler.Crawler.run">[docs]</a>    <span class="k">async</span> <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Starts the crawler with the given number of workers. Waits for the queue of URLs to be empty, then cancels the workers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># start by putting the starting url in the todo queue</span>
        <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">todo</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">starting_url</span><span class="p">)</span>

        <span class="c1"># create a list of workers</span>
        <span class="n">workers</span> <span class="o">=</span> <span class="p">[</span><span class="n">asyncio</span><span class="o">.</span><span class="n">create_task</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="p">())</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)]</span>

        <span class="c1"># wait for queue to be empty</span>
        <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">todo</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>

        <span class="c1"># free up resources</span>
        <span class="k">for</span> <span class="n">worker</span> <span class="ow">in</span> <span class="n">workers</span><span class="p">:</span>
            <span class="n">worker</span><span class="o">.</span><span class="n">cancel</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;crawled </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">done</span><span class="p">)</span><span class="si">}</span><span class="s1"> pages, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seen</span><span class="p">)</span><span class="si">}</span><span class="s1"> seen, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">total</span><span class="si">}</span><span class="s1"> total&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="Crawler.worker"><a class="viewcode-back" href="../../utils.html#utils.async_crawler.Crawler.worker">[docs]</a>    <span class="k">async</span> <span class="k">def</span> <span class="nf">worker</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A worker that crawls URLs from the queue until it is empty. If an error occurs while crawling a URL, it prints the error and continues with the next URL.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">url</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">todo</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">crawl</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
                <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delay</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error crawling </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">finally</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">todo</span><span class="o">.</span><span class="n">task_done</span><span class="p">()</span></div>

<div class="viewcode-block" id="Crawler.crawl"><a class="viewcode-back" href="../../utils.html#utils.async_crawler.Crawler.crawl">[docs]</a>    <span class="k">async</span> <span class="k">def</span> <span class="nf">crawl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Crawls a given URL, extracts new URLs from it, adds them to the queue, and stores the crawled URL. If an error occurs while getting the URL, it prints the error and returns.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            url (str): The URL to crawl.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">url</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">done</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Crawling </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">__client</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">follow_redirects</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">httpx</span><span class="o">.</span><span class="n">HTTPStatusError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error getting </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="n">parser</span> <span class="o">=</span> <span class="n">PasteParser</span><span class="p">()</span>
        <span class="n">parser</span><span class="o">.</span><span class="n">feed</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">parser</span><span class="o">.</span><span class="n">source_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">bs</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
            <span class="n">contents</span> <span class="o">=</span> <span class="n">bs</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;class&#39;</span><span class="p">:</span> <span class="n">parser</span><span class="o">.</span><span class="n">source_name</span><span class="p">})</span>

            <span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;./code_snippets/</span><span class="si">{</span><span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">parser</span><span class="o">.</span><span class="n">source_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.txt&quot;</span><span class="p">)</span>
            <span class="n">path</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="k">with</span> <span class="n">path</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">contents</span><span class="p">:</span>
                    <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">tag</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>

        <span class="n">urls</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse_links</span><span class="p">(</span><span class="n">base</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">),</span> <span class="n">html</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
        <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_links</span><span class="p">(</span><span class="n">urls</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">url</span><span class="p">)</span></div>


<div class="viewcode-block" id="Crawler.parse_links"><a class="viewcode-back" href="../../utils.html#utils.async_crawler.Crawler.parse_links">[docs]</a>    <span class="k">async</span> <span class="k">def</span> <span class="nf">parse_links</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">html</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parses HTML and extracts URLs from it.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            base (str): The base URL to resolve against if the extracted URLs are relative.</span>
<span class="sd">            html (str): The HTML to parse.</span>

<span class="sd">        Returns:</span>
<span class="sd">            set[str]: The set of extracted URLs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">parser</span> <span class="o">=</span> <span class="n">UrlParser</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">filter_func</span><span class="p">)</span>
        <span class="n">parser</span><span class="o">.</span><span class="n">feed</span><span class="p">(</span><span class="n">html</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">parser</span><span class="o">.</span><span class="n">found_links</span></div>

<div class="viewcode-block" id="Crawler.update_links"><a class="viewcode-back" href="../../utils.html#utils.async_crawler.Crawler.update_links">[docs]</a>    <span class="k">async</span> <span class="k">def</span> <span class="nf">update_links</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">urls</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Updates the set of seen URLs with the given URLs and adds the new URLs to the queue.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            urls (set[str]): The set of URLs to update with.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new</span> <span class="o">=</span> <span class="n">urls</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">seen</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seen</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">new</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">new</span><span class="p">:</span>
            <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">push_todo_url</span><span class="p">(</span><span class="n">url</span><span class="p">)</span></div>

<div class="viewcode-block" id="Crawler.push_todo_url"><a class="viewcode-back" href="../../utils.html#utils.async_crawler.Crawler.push_todo_url">[docs]</a>    <span class="k">async</span> <span class="k">def</span> <span class="nf">push_todo_url</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds a URL to the queue of URLs to crawl, if the number of URLs added to the queue has not reached the limit.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            url (str): The URL to add to the queue.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">total</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit</span><span class="p">:</span>
                <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">todo</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">url</span><span class="p">)</span></div></div>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">url_filter</span> <span class="o">=</span> <span class="n">UrlFilter</span><span class="p">(</span>
        <span class="n">allowed_domains</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;pastebin.com&quot;</span><span class="p">},</span>
        <span class="n">allowed_schemes</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;http&quot;</span><span class="p">,</span> <span class="s2">&quot;https&quot;</span><span class="p">},</span>
        <span class="n">allowed_filetypes</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;.html&quot;</span><span class="p">,</span> <span class="s2">&quot;.htm&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">},</span>
    <span class="p">)</span>

    <span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
        <span class="k">async</span> <span class="k">with</span> <span class="n">httpx</span><span class="o">.</span><span class="n">AsyncClient</span><span class="p">()</span> <span class="k">as</span> <span class="n">client</span><span class="p">:</span>
            <span class="n">crawler</span> <span class="o">=</span> <span class="n">Crawler</span><span class="p">(</span>
                <span class="n">client</span><span class="p">,</span>
                <span class="s2">&quot;https://www.pastebin.com/archive&quot;</span><span class="p">,</span>
                <span class="n">url_filter</span><span class="o">.</span><span class="n">url_filter</span><span class="p">,</span>
                <span class="n">workers</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                <span class="n">limit</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
            <span class="k">await</span> <span class="n">crawler</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

    <span class="n">asyncio</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, mpsr.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>